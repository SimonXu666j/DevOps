当大量主机需要同时从Registry下载镜像运行容器应用时（比如发布新版本，打补钉等情形），Registry 服务往往会成为镜像分发的瓶颈，应用镜像需要较长时间才能传送到所有主机上，使得应用发布的周期大大延长。不少用户采取了预先下载镜像的方法，让各节点事先分批获取镜像，然后在预定时刻统一启动应用。这种办法在一定程度上缓解了问题，但实质上并没有解决Registry分发的瓶颈。

利用Bit Torrent协议来加速镜像分发的系统（Decentralized Image Distribution，DID），其主要思路是允许在不同的host之间共享镜像，形成分布式的P2P下载网络，提高网络吞吐量。通过测试，我们验证了该系统在集群节点数目较多、镜像较大的情况下具有较大的性能优势。

管理界面Admin Console 
管理员可以通过Admin Console定义下发镜像的任务（如集群的大小、机器的IP地址、镜像URL等），并且可实时了解任务的完成情况。

控制器 
控制器是DID系统的核心组件，控制镜像分发的整个过程。当接收到来自Admin Console的镜像分发任务之后，控制器完成镜像的准备工作，并将具体的镜像下载任务下发给各个节点的客户端代理。

客户端代理 
客户端代理部署在集群的每个节点中，配合控制器的调度，完成整个镜像的分发过程。代理接收来自控制器的镜像下载任务，调用BT客户端下载镜像，并最终将镜像导入到Docker daemon中。

BT客户端 
部署在集群节点的BT客户端和部署在控制器中的BT客户端以及Tracker共同组成了一个完整的P2P文件传输系统。在整个镜像的分发过程中，它们利用BT协议完成镜像下载。

BT Tracker 
Tracker是BT系统的一部分，它存储了BT客户端下载过程中所需要的元数据信息，并协助各个BT客户端完成整个通信过程。


镜像分发原理
当用户通过Admin Console向DID系统提交一个镜像分发任务(Job)之后，控制器会进行以下处理：
通过本地的Docker Daemon REST API从Registry下载镜像到本地镜像仓库; 
调用Docker Daemon API从镜像仓库导出(export)镜像文件（镜像tar文件）; 
从镜像tar文件中抽取出组成镜像的所有layer并进行压缩; 
为每一个压缩后的layer制作BT种子文件; 
启动BT客户端载入所有压缩后的layer和相应的种子文件，此时控制器所在节点的BT客户端将成为一个Seeder; 
向各个客户端代理发送该镜像的下载任务。任务说明中包含了组成该镜像的所有layer的ID和其对应的种子文件的URL。

在客户端代理接收到来自控制器的镜像下载任务后会进行以下处理：
针对该镜像的每一个layer，通过调用检查其在本地是否已存在，把不存在的layer ID加入到待下载列表中； 
对下载列表中的layer，下载对应的种子文件，并启动BT客户端完成layer文件的下载； 
通过Docker daemon的API将下载完成的layer文件导入到Docker daemon中； 
重复步骤2和步骤3直到所有待下载layer全部被导入到Docker daemon中。注：每个layer的下载过程是并发执行的。

由于Docker的镜像是按照layer存储的，不同的镜像可共享layer，这种机制不仅减少了对存储的消耗，而且下载镜像时只需要下载缺少的layer即可，从而也就减少了镜像的下载时间。在上述DID的镜像分发过程中，我们将镜像拆分为多个layer利用BT协议进行传输。另外，由于BT协议原本是为因特网上的文件分发而设计的，有部分设计并不适用于局域网镜像集中分发的场景。比如，在BT下载过程中，每个客户端都会维护一个参与下载该文件的peer列表，默认情况下每隔1800秒BT客户端才会与Tracker进行一次通信来更新。在DID的设计中将这一时间修改为了1秒，以便各个节点的BT客户端可更快地获取其他peer的信息